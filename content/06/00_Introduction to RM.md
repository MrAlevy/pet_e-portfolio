# Scientific Investigation and Ethics - Reflection on AI Governance and Generative AI Impacts.

## Introduction

Generative AI has developed quickly since late 2022, significantly affecting various fields, especially Computer Science, where it began. Although AI is not new, its recent growth requires updated ethical guidelines to address new challenges. The ethical issues with AI are complex and involve legal, social, and professional aspects that must be considered worldwide. This assessment discusses the insights from Correa et al. (2023) and Deckard (2023), analyzing their viewpoints and suggesting recommendations for AI governance to address the identified gaps.
</br>

## Analysis of Current Ethical Guidelines

Correa et al. (2023) note that while AI is expanding rapidly, it brings different ethical concerns, such as privacy issues, bias, surveillance, and environmental effects, often affecting vulnerable groups the most. The authors find a lack of agreement on AI ethical standards due to different cultural and organizational perspectives. Their review of over 200 documents identifies recurring principles like transparency, fairness, accountability, and privacy. However, they point out that topics such as labor rights, environmental sustainability, and long-term risks like artificial general intelligence (AGI) are often overlooked.
</br>

Deckard (2023) emphasizes the need for a mix of skills to address AI's ethical challenges, combining ethical principles with technical knowledge. He also highlights the importance of understanding the social, political, and economic effects of AI in different regions. Engaging in public policy and working with experts from various fields are suggested to create more comprehensive ethical guidelines.
</br>

## Personal Views

A good approach to AI governance should aim to create a more unified set of ethical principles while allowing some flexibility for regional differences. This approach should include several key actions.
</br>

- Strengthening Interdisciplinary Collaboration
  As Deckard (2023) suggests, combining technical skills with ethical understanding is important for addressing AI's complex challenges. Ethical guidelines should involve not only AI specialists but also ethicists, sociologists, legal experts, and policymakers. This broad input can help identify risks and ethical issues that may not be considered from a purely technical view. For example, labor rights experts can highlight AI's impact on jobs, a topic that is often underrepresented in many ethical guidelines.
- Addressing Underrepresented Ethical Issues
  The gaps noted by Correa et al. (2023), such as labor rights and environmental sustainability, should be addressed. Ethical guidelines should clearly include principles that reduce the negative effects of AI on jobs and the environment. For instance, regulations could promote the development of AI systems that use less energy or offer alternative work opportunities for those affected by automation. Including labor rights in AI governance would also help prevent exploitation, like using AI for monitoring employees.
- Creating Practical and Enforceable Guidelines
  Moving from general ethical principles to practical solutions is essential. Guidelines should not only promote values like fairness and transparency but also provide specific practices to achieve them. For example, transparency could be implemented through required AI impact assessments, which would explain how an AI system might affect different people. To enforce these guidelines, governments and international bodies should work together to create regulatory organizations that can monitor compliance and handle violations.
- Incorporating Global Perspectives and Public Policy Engagement
  With different cultural and organizational views worldwide, reaching a global agreement on AI ethics may be challenging. However, setting a baseline of common principles could be a starting point, with room for regional adjustments. This would recognize cultural differences while still promoting key ethical standards. Participating in public policy discussions, as Deckard (2023) suggests, is also important for shaping laws that address AI's ethical challenges. For instance, policies could ensure that AI use in healthcare respects patient privacy and informed consent.
- Ensuring Regular Updates to Ethical Guidelines
  Since AI evolves quickly, ethical guidelines must be regularly reviewed and updated. Staying informed about new developments in AI, as Deckard (2023) advises, is important for addressing emerging ethical concerns. Governments, research institutions, and AI developers should work together to create adaptive regulatory frameworks that can respond to advancements like AGI.
  </br>

## Impact Assessment

The suggested recommendations would have several effects on legal, social, ethical, and professional issues.
</br>

- Legal Impact
  Enforceable regulations would help the legal system handle AI-related disputes. For example, requiring transparency in AI decision-making could help resolve cases where biased algorithms cause unfair results, such as discrimination in hiring or lending. Legal frameworks that include labor rights and environmental protections would also ensure that AI's negative effects are managed.
- Social Impact
  Including labor rights and environmental sustainability in AI ethics would promote social justice by protecting vulnerable groups and the planet. Addressing surveillance and bias concerns in AI would help build public trust, making AI's benefits more widely accessible. Ethical guidelines that include diverse viewpoints would reflect a broader range of social values, encouraging inclusive development.
- Ethical Impact
  Moving from general ethical principles to specific, practical guidelines would improve ethical compliance among AI developers. It would encourage them to consider the societal effects of their technologies from the start. Addressing gaps such as labor rights and environmental sustainability would lead to more complete ethical frameworks that cover a wider range of human and environmental concerns.
- Professional Impact
  For computing professionals, the focus on interdisciplinary collaboration would require ongoing education in ethics, law, and social sciences. It would also encourage them to join public policy discussions, as their technical skills would be valuable in shaping regulations. Clear and enforceable ethical guidelines would give developers a better understanding of their professional responsibilities, ensuring their work aligns with social values.
  </br>

## Conclusion

The rapid growth of generative AI presents unique ethical challenges that need a careful approach to governance. While existing AI ethical principles cover some areas, gaps like labor rights and environmental sustainability must be addressed. This assessment highlights necessities of strengthening interdisciplinary collaboration, including underrepresented issues, creating practical guidelines, engaging in public policy, and keeping ethical frameworks up to date. These actions will help align AI development with legal, social, ethical, and professional standards, making the technology more beneficial for society.
</br>

## References

- Corrêa, N.K. et al. (2023) ‘Worldwide AI ethics: A review of 200 guidelines and recommendations for AI governance’, Patterns (New York, N.Y.), 4(10), p. 100857.
- Deckard, R. (2023) ‘What are ethics in AI?’, BCS. Available from: https://www.bcs.org/articles-opinion-and-research/what-are-ethics-in-ai/ [Accessed 26 October 2024].
